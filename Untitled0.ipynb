{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPvz/VbwRXlzQ5Cu/fABMl3",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/burcugeyik/yapayzeka/blob/main/Untitled0.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "D9kNbuzXCV0d"
      },
      "outputs": [],
      "source": [
        "!pip install --upgrade tensorflow\n",
        "!pip install opencv-python-headless"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        " Resimlerin Okunması, resim ve etiket dizilerinin oluşturulma aşaması"
      ],
      "metadata": {
        "id": "5v_scJ9ACgVW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.preprocessing.image import img_to_array\n",
        "from tensorflow.keras.preprocessing.image import load_img\n",
        "import numpy as np\n",
        "import random\n",
        "import math\n",
        "import csv\n",
        "import cv2\n",
        "import os"
      ],
      "metadata": {
        "id": "09DFY38NCoGm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "inputBasePath içerisinde her bir sınıf için o sınıf adıyla oluşturulmuş bir ktasör vardır ve her klasör içerisinde o sınıfa ait resimler yer almaktadır, bu resimler her analiz adımında yeniden okunup işlenebilir ancak bu okuma sürecini yeniden yeniden yapmamak için resimler bir kereye mansus okunup, istenirse yeniden boyutlandırılıp, istenirse fitre uygulanıp vs. daha sonra bir numpy array olarak kaydedilir daha sonrakı analiz işlemlerinden direkt bu array oxunarak hizlica işlem yapılabilir oluştutulan array'ler outputBasePlath yoluna kaydedilecek"
      ],
      "metadata": {
        "id": "DoeKfIqsCq0W"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "InputBasePath   =  \"C:\\Users\\ASUS\\OneDrive\\Masaüstü\\horsesandrabbits\\images\"\n",
        "outputBasePath  =  \"C:\\Users\\ASUS\\OneDrive\\Masaüstü\\horsesandrabbits\\imagearrays\" #bu klasörlerin daha once olusturulmuş olması gerek"
      ],
      "metadata": {
        "id": "Q025a9kICsA8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "resimler yeniden boyutlandınılmak istenirse genişlik ve yükseklik değerlen burada tanımtamyor özellikle state-of-art modeller resimleri belli ölçülerde daha iyi işiyor ideal değerleri öğrenip ona göre boyut verilebilir\n",
        "\n",
        "Imagenet ile eğitilen VGG16, VGG19 ve ResNet modelleri 224x224 boyutunda, Inception V3 ve Xception ise 299x299 boyutunda girdiye intiyaç duyar"
      ],
      "metadata": {
        "id": "7A_9bKL5CxbJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "image width 224\n",
        "image height 224"
      ],
      "metadata": {
        "id": "svGcPT7hCyLG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "sınıf adlarını tutan bir dizi tanımlanıyor, bu sınıf adları aynı zamanda inputBasePathte yer alan klasör isimleri\n",
        "\n"
      ],
      "metadata": {
        "id": "DC-DWo0PC2Cj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "classes = ['rabbit','horse']"
      ],
      "metadata": {
        "id": "dpGTMxVQC25A"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "os.chdir(inputBasePath) #chdir -> change directory, inputBasePath yoluyla verilen dizine git\n",
        "\n",
        "X = [] # resimlerin yani girdileri yani X değerlerini tutmak için dizi\n",
        "Y = [] # etiketleri yani Y değerlerini tutmak için dizi. her bir resmin etiketi içinde yer aldığı klasörün adı zaten\n",
        "\n",
        "i = 0\n",
        "for class1 in classes:\n",
        "  os.chdir(class1) #base yoldan sonra sıradaki sınıfı gösteren klasöre konumlan\n",
        "  print('-> ' +class1) #o an üzerinde bulunan sınıfı (klasörün adını) yaz\n",
        "  for files in os.listdir(' ./' ): # nokta mevcut dizini gösteriyor. ./ mevcut dizinin altındakiler\n",
        "    img = cv2.imread(files) #dosya yolundan resmi binary array olarak okuma.resmi grayscale(gri şekilde okutmak) almak için ikinci parametreye 0 yazılır\n",
        "    img = cv2.resize(img, (image_width,image_height)) #isteğe bağlı olarak resize edilebilir\n",
        "    X.append(img) #resmi oluşturan bit dizisini X'e ekle\n",
        "    Y.append(class1) # bu resmin sınıfı içinde bulunduğu klasör adı. resmin etiketi olarak bunu Y'ye ekle\n",
        "    i = i + 1\n",
        "  os.chdir('..') #bir üst dizine çık. bu sınıfla ve bunu içeren klasörler işimiz bitti\n",
        "print(\"X : \",len(X))\n",
        "print(\"Y : \",len(Y))\n",
        "\n",
        "X = np.array(X).reshape(-1,image_width,image_height,3) #-1 ile verilen ilk değerin yerinde toplam resim adedi var;\n",
        "                #bu aynı kalacak. diğer parametreler verilen width ve height'e göre ve resmin renkli olduğunu\n",
        "                #belirten 3 ile yeniden şekillendirilecek\n",
        "Y = np.array(Y) #etiket adlarını içeren Y'yi reshape etmeye gerek yok.\n",
        "\n",
        "print(\"X :\",X.shape)\n",
        "print(\"Y :\",Y.shape)\n",
        "\n",
        "print(\"X :\",len(X))\n",
        "print(\"Y :\",len(Y))\n",
        "\n",
        "os.chdir('..') #bir üst dizine çıkıp sonra imagearrays klasörüne gidersek zaten outputBasePath'e ulaşmış olacağız\n",
        "os.chdir(\"imagearrays\")\n",
        "# üstteki iki satır yerine bunu direkt chdir(outputBasePath) olarak da yapabilirdik\n",
        "np.save(str(image_width)+'x'+str(image_height)+'_images', X) #diziyi kaydederken dosya adını en x boy_images olarak adlandırır\n",
        "                                                             #'224x224_images' gibi\n",
        "np.save(str(image_width)+'x'+str(image_height)+'_labels', Y) #diziyi kaydederken dosya adını en x boy_labels olarak adlandırır\n",
        "\n",
        "print(\"[ INFO - STAGE1 ] NUMPY ARRAY CREATION COMPLETED \\n \")\n",
        "\n"
      ],
      "metadata": {
        "id": "3Rf0qGHGC7oM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Sınıflandırma işlemleri\n",
        "\n",
        "Bu aşamadan sonra daha önce oluşturulan array'ler okunarak işlem yapılacak"
      ],
      "metadata": {
        "id": "JyQPgzKPC8l-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import classification_report\n",
        "from sklearn.model_selection import train_test_split\n",
        "from keras.utils.np_utils import to_categorical\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.metrics import mean_squared_error\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import BatchNormalization\n",
        "from tensorflow.keras.layers import Conv2D\n",
        "from tensorflow.keras.layers import MaxPooling2D\n",
        "from tensorflow.keras.layers import MaxPool2D #üstteki Maxpooling2D ile aynı şey. ister onu ister bunu kullan.\n",
        "#kodda ikisi de kullanıldığı için eklendi. yoksa biri ile yapılsaydı da olurdu.\n",
        "from tensorflow.keras.layers import Activation\n",
        "from tensorflow.keras.layers import Flatten\n",
        "from tensorflow.keras.layers import Dropout\n",
        "from tensorflow.keras.layers import Dense\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.optimizers import SGD\n",
        "\n"
      ],
      "metadata": {
        "id": "0EiSFKc8DCKK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "data önce numpy array olarak kaydedilen görüntüleri(data) ve sınıf(label) etiketlerini oku"
      ],
      "metadata": {
        "id": "CxcBEE8XDGll"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data = np.load(\"C:\\Users\\ASUS\\OneDrive\\Masaüstü\\horsesandrabbits\\imagearrays\\224X224_images.npy\")\n",
        "labels = np.load(\"C:\\Users\\ASUS\\OneDrive\\Masaüstü\\horsesandrabbits\\imagearrays\\224X224_labels.npy\")\n",
        "data.shape"
      ],
      "metadata": {
        "id": "TSwChh0EDIp-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Label Encoding\n",
        "\n",
        "array den okunan etiketlerin orijinal halde,string şeklinde bunları 0 1 2 şeklinde yani label encoding yapacağız"
      ],
      "metadata": {
        "id": "SYNgUIw1DNaX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "labelEn = LabelEncoder() #string olan etiketleri 0 1 2 şeklinde kodla\n",
        "labels = labelEn.fit_transform(labels)\n",
        "labels = to_categorical(labels)"
      ],
      "metadata": {
        "id": "2EMdBN1GDOLJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Train-Test Split"
      ],
      "metadata": {
        "id": "Zpj2JFaEDR3p"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#veri array'e kaydedilmeden önce reshape edildiğinden array den okununca da düzgün gelir. yeniden reshape etmeye gerek yok\n",
        "#eğer array'e atarken son değer 3 olarak yazılmasaydı burada reshape gerekirdi\n",
        "\n",
        "#data = dalabelEn = LabelEncoder() #string olan etiketleri 0 1 2 şeklinde kodla\n",
        "#data - data.serhape(-1,image_width , image_height , 3)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "#train -test split\n",
        "#%20 test %80 eğitim seti olacak şekilde böl\n",
        "x_train, x_test, y_train, y_test = train_test_split(data, labels, test_size= .20, shuffle=True)\n",
        "\n",
        "\n",
        "print(\n",
        "    \"\"\"\n",
        "x_train shape : {}\n",
        "x_test shape : {}\n",
        "y_train shape : {}\n",
        "y_test shape : {}\n",
        "    \"\"\".format(x_train.shape, x_test.shape, y_train.shape, y_test.shape))\n"
      ],
      "metadata": {
        "id": "L2SmMSMIDZ-R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Normalizasyon (bu adım opsiyonel)\n",
        "\n",
        "verileri normalize edilerek piksel değer aralıklarını 0-1 aralığına çekilip daha hızlı işlem yapılması sağlanabilir. Normalizasyon ,işlem hızını arttırır ama her görüntü için başarı artışı getirmeyebilir, belki başarıyı düşürebilir."
      ],
      "metadata": {
        "id": "eGpaMzSrDcta"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x_train_mean = np.mean(x_train)\n",
        "x_train_std = np.std(x_train)\n",
        "\n",
        "x_test_mean = np.mean(x_test)\n",
        "x_test_std = np.std(x_test)\n",
        "\n",
        "x_train = (x_train - x_train_mean) / x_train_std\n",
        "x_test = (x_test - x_test_mean) / x_test_std"
      ],
      "metadata": {
        "id": "HZ4qmB5sDdk_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Train-Validation Split\n",
        "\n",
        "%20 test-%10 validation seti olacak şekilde ayır\n",
        "\n",
        "validation datası, modelin eğitimi esnasında train verisini doğrulamak için yani eğitim işlemi esnasındaki  test sürecini gerçekleştirmek için kullanılıyor. x_test ve y_tesst ise eğitim süreci bittikten sonra eğitilen modeli daha önce hiç blmediği verilerle test etmek için"
      ],
      "metadata": {
        "id": "m0kWoaruDjzO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x_train, x_validation, y_train, y_validation = train_test_split(x_train, y_train, test_size= .10, shuffle=True,random_state=42)\n"
      ],
      "metadata": {
        "id": "ezVb8wPhDkpf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Model tanımlama\n",
        "\n",
        "kendimize göre bir model oluşturan ve bunu geri döndüren bir fonksiyon yazalım"
      ],
      "metadata": {
        "id": "pekYRztdDmrN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def model1(input_shape=(image_width ,image_height ,3), num_classes = 2): #parametrelerin varsayılan değerleri var\n",
        "#modelin giriş shape'i ve class sayısı= 3\n",
        "#burada oluşturulan model VGG16 mimarisi aslında. değiştirilebilir.\n",
        "\n",
        "#ourada oluşturulan model VG616 Mimarist astinda. degiştirilebil\n",
        "model = Sequential()\n",
        "chanDim =\n",
        "model.add(Conv2D (64, (3,3), padding=\"same\", input_shape=input_shape))\n",
        "model.add(Activation(\"relu\"))\n",
        "model.add(BatchNormallization(axis-chanDim))\n",
        "model.add(Conv2D(64, (3,3), padding=\"same\"))\n",
        "model.add(Activation(\"relu\"))\n",
        "model.add(BatchNormalization(axis=chanDim))\n",
        "model.add(MaxPooling2D (pool_size=(2, 2)))\n",
        "#2.Layer (CONV => RELU => CONV => RELU) * 2 => POOL\n",
        "model.add(Conv2D(128, (3,3), padding=\"same\"))\n",
        "model.add(Activation(\"relu\"))\n",
        "model.add(BatchNormalization(axis-chanDim))\n",
        "model.add(Conv2D(128, (3,3), padding=\"same\"))\n",
        "model.add(Activation(\"relu\"))\n",
        "model.add(BatchNormalization (axis-chanDim))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "#3. Layer (CONV => RELU => CONV => RELU) * 2 => POOL\n",
        "model.add(Conv2D (256, (3,3), padding=\"same\"))\n",
        "model.add(Activation(\"relu\"))\n",
        "model.add(BatchNormalization(axis chanDim))\n",
        "model.add(Conv2D (256, (3,3), padding=\"same\"))\n",
        "model.add(Activation(\"relu\"))\n",
        "model.add(BatchNormalization (axis-chanDim))\n",
        "model.add(Conv2D(256, (3,3), padding=\"same\"))\n",
        "model.add(Activation(\"relu\"))\n",
        "model.add(BatchNormalization(axis-chanDim))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "#4. Layer (CONV => RELU => CONV => RELU) 2 => POOL\n",
        "model.add(Conv2D (512, (3,3), padding=\"same\"))\n",
        "model.add(Activation(\"relu\"))\n",
        "model.add(BatchNormalization (axis=chanDim))\n",
        "model.add(Conv2D (512, (3,3), padding=\"same\"))\n",
        "model.add(Activation(\"relu\"))\n",
        "model.add(BatchNormalization(axis=chanDim))\n",
        "model.add(Conv2D (512, (3,3), padding=\"same\"))\n",
        "model.add(Activation(\"relu\"))\n",
        "model.add(BatchNormalization (axis-chan Dim))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "#5. Layer (CONV => RELU => CONV => RELU) 2 => POOL\n",
        "model.add(Conv2D (512, (3,3), padding=\"same\"))\n",
        "model.add(Activation(\"relu\"))\n",
        "model.add(BatchNormalization (axis-chanDim))\n",
        "model.add(Conv2D (512, (3,3), padding=\"same\"))\n",
        "model.add(Activation(\"relu\"))\n",
        "model.add(BatchNormalization(axis=chanDim))\n",
        "model.add(Conv2D (512, (3,3), padding=\"same\"))\n",
        "model.add(Activation(\"relu\"))\n",
        "model.add(BatchNormalization (axis-chanDim))\n",
        "model.add(MaxPooling2D (pool_size=(2, 2)))\n",
        "#1. TAM BAĞLANTI KATMANI\n",
        "model.add(Flatten())\n",
        "model.add(Dense (4096))\n",
        "model.add(Activation(\"relu\"))\n",
        "Batc model.add(BatchNormalization())\n",
        "model.add(Dropout(0.5))\n",
        "#2. TAM BAĞLANTI KATMANI\n",
        "model.add(Flatten())\n",
        "model.add(Dense (4096))\n",
        "model.add(Activation(\"relu\"))\n",
        "model.add(Batch Normalization())\n",
        "model.add(Dropout (0.5))\n",
        "# SOFTMAX\n",
        "model.add(Dense(num_classes))\n",
        "model.add(Activation(\"softmax\"))\n",
        "return model\n"
      ],
      "metadata": {
        "id": "olWch50aDrnz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# bir başka model\n",
        "def model2(input_shape=(image_width, image_height,3), num_classes = 2):\n",
        "model Sequential()\n",
        "model.add(Conv2D(32, kernel_size(3, 3), activation-'relu, padding \"Same', input_shape-input_shape))\n",
        "model.add(Conv2D(64, kernel_size-(3, 3), activation-'relu, padding \"Same',))\n",
        "model.add(MaxPool2D(pool_size = (2, 2)))\n",
        "model.add(Dropout (8.5))\n",
        "model.add(Conv2D(128, (3, 3), activation-relu\", padding. \"Same\"))\n",
        "model.add(Conv2D(64, (3, 3), activation 'relu\", padding \"Same'))\n",
        "model.add(MaxPool2D(pool_size=(2, 2)))\n",
        "model.add(Dropout (8.5))\n",
        "model.add(Flatten())\n",
        "model.add(Dense(128, activation-'relu'))\n",
        "model.add(Dense (256, activation-'relu\"))\n",
        "model.add(Dense (512, activation-relu'))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(num_classes, activation- 'softmax')) #ikili sımıflama olsaydı sigmoid kullanılırdı.\n",
        "#bu durumda zaten num classes 1 olurdu. yani çıkış nöronu 1 tane olurdu.\n",
        "return model"
      ],
      "metadata": {
        "id": "qHLGkvm3Dvb1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 106
        },
        "outputId": "370da356-ee74-4e11-b903-a0c089e0ec85"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "error",
          "ename": "SyntaxError",
          "evalue": "unterminated string literal (detected at line 8) (<ipython-input-1-dc825ba23b74>, line 8)",
          "traceback": [
            "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-1-dc825ba23b74>\"\u001b[0;36m, line \u001b[0;32m8\u001b[0m\n\u001b[0;31m    model.add(Conv2D(128, (3, 3), activation-relu\", padding. \"Same\"))\u001b[0m\n\u001b[0m                                                                  ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m unterminated string literal (detected at line 8)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model1 = model2()\n",
        "model.summary()"
      ],
      "metadata": {
        "id": "EpI2Wxt2DwEL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Modeli görselleştirme"
      ],
      "metadata": {
        "id": "7__GIoFDD0p6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pip install pydot #görselleştirme için gerekli kütüphane"
      ],
      "metadata": {
        "id": "fajrPdn4D4t2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tf.keras.utils.plot_model(model, to_file='model_plot.png', show_shapes=True, show_layer_names=True )"
      ],
      "metadata": {
        "id": "Tj2156VlD6Et"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Optimizer tanımla\n",
        "\n",
        "Eğitim işlemi sonucunda ağın bulduğu sonuç ile gerçekte olması gereken sonuç arasındaki fark ile oluşan hatayı loss function ile hesaplıyoruz. Loss fonksiyonu çoklu sınıflamalarda \"categorical_crossentropy\", ikili sınıflamada \"binary_crossmtropy\" olarak seçiliyor. Loss hesaplandıktan sonra geriye yayılımla tüm parametrelerin optimize edilmesi gerekiyor. Bu aşamada kullanılan adım uzunluğu \"learning rate\" in (LR) duruma göre adaptif bir şekilde değiştirilmesi sonucu daha verimli kılar. \"Learning rate\" çok küçük olursa işiem uzun sürer, çok büyük olursa hatanın minimum değeri kaçırılabilir. Bu nedenle LR optimize edilmelidir. Bu iş için adaptif momentum optimizer yani \"adam\" optimizer kullanacağız.\n"
      ],
      "metadata": {
        "id": "FIR08DvpD8oB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "optimizer = Adam(learning_rate=0.0001, beta_2=0.999, epsilon=None, decay=0.0, amsgrad=False)"
      ],
      "metadata": {
        "id": "jqkjFiuDD_Yv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "LR annealer tanımlama\n",
        "\n",
        "Eğitim esnasında monitör edilen parametrede ilerleme olmuyorsa LR değiştirilir. Bu işlemi Keras.callbacks içindeki ReduceLROnPlateau fonksiyonu ile yapabiliriz."
      ],
      "metadata": {
        "id": "lNDTxZ3sEAS_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Set a Learning rate annealer\n",
        "\n",
        "from tensorflow.keras.callbacks import ReduceLROnPlateau\n",
        "learning_rate_reduction ReduceLROnPlateau (monitor 'val_accuracy', patience-3, verbose 1, factor-0.5, min_lr-0.00001)"
      ],
      "metadata": {
        "id": "Kfvh47_pEC_L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Modeli derle\n",
        "\n",
        "Loss fonksiyonu çoklu sınıflamalarda \"categorical_crossentropy\", ikili sınıflamada \"binary_crossentropy\" olarak seçilir. burada üç sınıf olduğu için categorical_crossentropy, çoklu sınıflamada modelin sonundaki sınıflayıcıda (flatten'den sonraki kısım) çıkışta sınıf sayısı kadar nöron olur.\n",
        "\n",
        "İkili sınıflama yapılıyorsa çıkış nöron sayısı tektir. bu tek çıkış 0 veya 1 olarak bir değer verir. bu durumda loss fonksiyonu binary_crossentropy olur.\n",
        "\n",
        "DİKKAT: iki sınıfılı bir veri var/yok şeklinde ise ikili sınıflama uygundur. ama kırmızı-siyah, elma-çilek vs. gibi (yani kırmızı kırmızı değil şeklinde değil veya elma elma değil şeklinde yani var yok halinde değil) ve bu sınıflar 1, 2 gibi kodlanmışsa, çıkışta yine 2 nöron olur ve sınıflamada kategoriktir, binary değildir. bu durum aslında yapılan kurgu ile ilgili.\n"
      ],
      "metadata": {
        "id": "70pDM-KUEIy0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(optimizer=optimizer, loss='categorical_crossentropy', metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "wAw4ISHcEJct"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "epoch ve batch size tanımla\n",
        "\n",
        "epoch = model kaç iterasyon çalışacak batch size = resimler modele bit dizisi matrisleri olarak alınır. her bir adımda kaç resmin bit dizisi alınacak, yani kaç resim alınacak. bir seferde alınan resimler yığın (batch), yığındaki resim sayısı batch size\n",
        "\n",
        "cost fonksiyonu her bir batch için hesaplanır, buna göre geri yayılım yapılır. her bir resim için yapılsaydı süreç uzardı (belki hesap daha hassas olurdu), batch size azaldıkça daha ince hesap yapılır ama süreç uzar, batch size artarsa cost hesabı daha üstünkörü olur, başarı düşebilir. bu nedenle batch size optimum şekilde seçilmeli."
      ],
      "metadata": {
        "id": "hU02lzTcEQpw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "epc = 5\n",
        "bs = 8"
      ],
      "metadata": {
        "id": "2GchHfZgERN3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "modeli çalıştır\n",
        "\n",
        "modeli fit edince çalışır. modelin her bir aşamasındaki sonuçlar history değişkenine raporlanır"
      ],
      "metadata": {
        "id": "uo3gKL8MEUak"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "history = model.fit(x_train, y_train, batch_size=bs,\n",
        "                          epochs=epc, validation_data=(x_validate, y_validate),\n",
        "                          verbose = 1, callbacks=[learning_rate_reduction])\n"
      ],
      "metadata": {
        "id": "qKHWuJ0rEW8d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#history nin içindeki history değerinin anahtarları raporu alınabilecek değerlerin adlarını gösterir\n",
        "history.history.keys()"
      ],
      "metadata": {
        "id": "LXFnpDTGEcLv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Doğruluk grafiğini çiz"
      ],
      "metadata": {
        "id": "lzOxBIPXEdIr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.plot(history.history['accuracy'])\n",
        "plt.plot(history.history['val_accuracy'])\n",
        "plt.title('model accuracy')\n",
        "plt.ylabel('accuracy')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'test'], loc='upper left')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "Lt1jcQNNEgr3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 211
        },
        "outputId": "b6f93a4d-1ce3-47e1-ff57-a5c49e217b3a"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'history' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-2-c82fbc01f036>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpyplot\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'accuracy'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'val_accuracy'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtitle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'model accuracy'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'history' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Hata grafiğini çiz"
      ],
      "metadata": {
        "id": "UhqB7VxoEmL1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "plt.plot(history.history['loss'])\n",
        "plt.plot(history.history['val_loss'])\n",
        "plt.title('model loss')\n",
        "plt.ylabel('loss')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'test'], loc='upper left')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "30OunzodEpou"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import itertools\n",
        "def plot_confusion_matrix(cm, classes,\n",
        "                          normalize=False,\n",
        "                          title='Confusion matrix',\n",
        "                          cmap=plt.cm.Blues):\n",
        "  \"\"\"\n",
        "  This function prints and plots the confusion matrix.hasattr\n",
        "  Normalization can be applied by setting 'normalize=True'\n",
        "  \"\"\"\n",
        "\n",
        "  plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
        "  plt.title(title)\n",
        "  plt.colorbar()\n",
        "  tick_marks = np.arange(len(classes))\n",
        "  plt.xticks(tick_marks, classes, rotation=45)\n",
        "  plt.yticks(tick_marks, classes)\n",
        "\n",
        "  if normalize:\n",
        "      cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
        "\n",
        "  thresh = cm.max() / 2.\n",
        "  for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
        "      plt.text(j, i, cm[i, j],\n",
        "               horizontalalignment=\"center\"\n",
        "               color=\"white\" if cm[i, j] > thresh else \"black\")\n",
        "\n",
        "  plt.tight_layout()\n",
        "  plt.ylabel('True label')\n",
        "  plt.xlabel('Predicted label')"
      ],
      "metadata": {
        "id": "dI3B7RzNEs9E"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Y_pred = model.predict(x_test)\n",
        "y_pred_classes = np.argmax(Y_pred,axis = 1)\n",
        "# Convert validation observations to one hot vectors\n",
        "y_true = np.argmax(y_test,axis = 1) #test süreci için Y_ture = np.orgmax(y_test,axis = 1)\n",
        "# compute the confusion matrix\n",
        "confusion_mtx = confusion_matrix(y_true, y_pred_classes)\n",
        "# plot the confusion matrix\n",
        "plot_confusion_matrix(confusion_mtx, classes = range(3))"
      ],
      "metadata": {
        "id": "ev9oTLcHEtzD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import classification_report\n",
        "report = classification_report(y_true, y_pred_classes)\n",
        "print(report)"
      ],
      "metadata": {
        "id": "HQvQ8TYrExeC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "istenirse eğitilen model daha sonra kullanılmak üzere, hesaplanan ağırlıkları ile kaydedilebilir. bunun için de bir yol tanımlamsı yapabiliriz"
      ],
      "metadata": {
        "id": "qXAZSdP8E0xY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "bir başka test işlemli ve confusion matrix çizimi\n",
        "\n",
        "bu kez test dataları kullanılarak hesap yapılıyor. confusion matrix stil olarak daha farklı"
      ],
      "metadata": {
        "id": "w8RnBEeqE5HN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "preds = model.predict(x_test)\n",
        "y_pred = np.zeros_like(preds)\n",
        "y_pred[np.arange(len(preds)), preds.argmax(1)] = 1\n",
        "classes = ['horse','rabbit']\n",
        "confusionMatrix = np.zeros((len(classes),len(classes)))\n",
        "\n",
        "for i in range(len(y_test)):\n",
        "\n",
        "  if np.array_equal(y_pred[i],y_test[i]):\n",
        "    index = np.argmax(y_test[i])\n",
        "    confusionMatrix[index,index] += 1\n",
        "  else:\n",
        "    index1 = np.argmax(y_test[i])\n",
        "    index2 = np.argmax(y_pred[i])\n",
        "    confusionMatrix[index1,index2] += 1\n",
        "\n"
      ],
      "metadata": {
        "id": "CGU-FnnXE5sw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "from sklearn.metrics import confusion_matrix\n",
        "import seaborn as sns\n",
        "print(\"CLASSIFICATION REPORT\")\n",
        "print(classification_report(y_test, y_pred))\n",
        "print(\"ACCURACY SCORE : \")\n",
        "print(accuracy_score(y_test, y_pred))\n",
        "cm = accuracy_score(y_test, y_pred)\n",
        "sns.set(font_scale=0.8)\n",
        "sns.heatmap(confusionMatrix,annot=True, linewidths=1.0, cbar=False)\n",
        "print(\"---------------------------------------------------\")\n",
        "print(\"Confusion Matrix : \")\n",
        "print(confusionMatrix)\n",
        "print(\"---------------------------------------------------\")\n",
        "\n"
      ],
      "metadata": {
        "id": "yth0lEhJE_Ny"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Veri arttırımı (Data Augmentation)\n",
        "\n",
        "Bu işlem opsiyonel olarak yapılır. Daha iyi öğrenme ve overfitting probleminin önüne geçmek için elimizdeki mevcut verileri belirli biçimde dönüştürerek yeni yapay örnekler elde edip, elimizdeki örnekleri çeşitlendirebiliriz"
      ],
      "metadata": {
        "id": "CuTjnM7RFDut"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#ImageDataGenerator ile veri arttırım modelini kurgula ve datagen değişkenlerini ata\n",
        "datagen = ImageDataGGenerator(\n",
        "        featurewise_center=False,  #set input mean to 0 over the dataset\n",
        "    \tsamplewise_center=False,  #set each sample mean to 0\n",
        "    \tfeaturewise_std_normalization=False,  #divide inputs by std of the dataset\n",
        "    \tsamplewise_std_normalization=False,  #divide each input by its std\n",
        "      zca_whitening=False, #apply ZCA whitening\n",
        "        rotation_range=10,  # randomly rotate images in the range (degrees, 0 to 180) 10 degrees\n",
        "    \tzoom_range = 0.1, # Randomly zoom image %10\n",
        "    \twidth_shift_range=0.1, #randomly shift images horizontally (fraction of total width ) %10\n",
        "        height_shift_range=0.1, #randomly shift images vertically (fraction of total height) %10\n",
        "    \thorizontal_flip=False, # randomly flip images\n",
        "    \tvertical_flip=False # randomly flip images\n",
        "                        )\n",
        "\n",
        "datagen.fit(x_train) #datagen'i x_train üzerinden çalıştır ve veri üret"
      ],
      "metadata": {
        "id": "J2heeFxBFG0u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Üretilen resimlerden görüntüle"
      ],
      "metadata": {
        "id": "OhN5tptPFJqs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from matplotlib import pyplot\n",
        "for X_batch, y_batch in datagen.flow(x_train, y_train, batch_size=9):\n",
        "\t# create a grid of 3x3 images\n",
        "\tfor i in range(0, 9):\n",
        "\t\tpyplot.subplot(330 + 1 + i)\n",
        "\t\tpyplot.imshow(X_batch[i].reshape(224, 224,3))\n",
        "\t# show the plot\n",
        "\tpyplot.show()\n",
        "\tbreak"
      ],
      "metadata": {
        "id": "iX-hvFxEFMz5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 211
        },
        "outputId": "07a8ed5d-5af7-45b2-fab6-de82e6c657ce"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'datagen' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-3-0dfd7ca97594>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mmatplotlib\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpyplot\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mX_batch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_batch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdatagen\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m9\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m         \u001b[0;31m# create a grid of 3x3 images\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m9\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m                 \u001b[0mpyplot\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msubplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m330\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'datagen' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Veri arttırımı ile birlikte modeli fit et\n",
        "\n",
        "Veri arttırımı uygulayarak modeli tekrar fit et ve sonuçları izle. Bunun için fit_generator metodu kullannılır."
      ],
      "metadata": {
        "id": "p1wEUs_iFRbz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "history = model.fit_generator(datagen.flow(np.array(x_train),np.array(y_train), batch_size=bs),\n",
        "                              epochs = epc, validation_data = datagen.flow(np.array(x_validation),\n",
        "                             np.array(y_validation), batch_size=bs),verbose = 1,\n",
        "                              steps_per_epoch=x_train.shape[0] // bs,\n",
        "                              callbacks=[learning_rate_reduction])\n"
      ],
      "metadata": {
        "id": "EHeK-oiFFTYx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Bu işleminardından model tekrar test edilebilir,sonuçlara confusion matrix'e yukarıda yapılanların benzerleri ile ulaşılabilir."
      ],
      "metadata": {
        "id": "nF7A4OPXFWdI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "PRE_TRAINED MODEL UYGULAMA"
      ],
      "metadata": {
        "id": "x-sE79ccFat2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from kera.applications.vgg16 import VGG16, preprocess_input\n",
        "base_model = VGG16(\n",
        "    weights='imagenet',\n",
        "    include_top=False,\n",
        "    input_shape=(image_width, image_height, 3)\n",
        ")"
      ],
      "metadata": {
        "id": "pVPQzwoGFe5P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "NUM_CLASSES=2\n",
        "model1 = Sequential()\n",
        "model1.add(base_model)\n",
        "model1.add(Flatten())\n",
        "model1.add(Dropout(0.5))\n",
        "model1.add(Dense(NUM_CLASSES, activation='softmax'))\n",
        "\n",
        "model.layers[0].trainable = False #ilk katmana eklenen vgg16 modelini tekrar train etme,\n",
        "                                #imagenet'te train edilmiş ağırlıkları kullan"
      ],
      "metadata": {
        "id": "e7sd8xJUFh-a"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "metadata": {
        "id": "OaAe1PJ2Fj6K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(optimizer=optimizer, loss='categorical_crossentropy', metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "fndKGNBMFmi4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "istersen data augmentation olmadan fit et"
      ],
      "metadata": {
        "id": "h0cHOsnwFnlS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "history = model.fit(x_train,y_train, batch_size=bs,\n",
        "                    epochs = epc, validation_data = (x_validation, y_validation),\n",
        "                    verbose = 1, callbacks=[learning_rate_reduction])"
      ],
      "metadata": {
        "id": "V1ZywBpYFs1D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "istersen data augmentation kullanarak fit et"
      ],
      "metadata": {
        "id": "WB9FEYvXFvSN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "history = model.fit_generator(datagen.flow(np.array(x_train),np.array(y_train), batch_size=bs),\n",
        "                              epochs = epc, validation_data = datagen.flow(np.array(x_validation),\n",
        "                             np.array(y_validation), batch_size=bs),verbose = 1,\n",
        "                              steps_per_epoch=x_train.shape[0] // bs,\n",
        "                              classbacks=[learning_rate_reduction])"
      ],
      "metadata": {
        "id": "H6phqRm4F0IU"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}